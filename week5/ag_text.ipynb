{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ag_text.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "F5BWFgv-x05q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "fde1b86c-f9b5-4238-ea59-de93577c4ea6"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-CVJxV2ex2xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbdb38ea-25f4-4ea0-b604-fe48e73ae64d"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from string import punctuation\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, BatchNormalization, Activation,Flatten\n",
        "from keras.layers import Embedding, Input, Dense, Dropout, Lambda, MaxPooling1D\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XZ0RIob0x4Wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alphabet = 'abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:’\"/|_#$%ˆ&*˜‘+=<>()[]{} '\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOX-XCrBqnMy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Embedding and net design Inspired from *Very Deep Convolutional Networks for Text Classification* (https://arxiv.org/abs/1606.01781)."
      ]
    },
    {
      "metadata": {
        "id": "O8RAmICzx-MY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_dict = {}\n",
        "max_len=1024\n",
        "dataset_path='/content/gdrive/My Drive/ag_data/'\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "for i,c in enumerate(alphabet):\n",
        "  char_dict[c] = i+1\n",
        "\n",
        "\n",
        "def char2vec(text):\n",
        "\t\tdata = np.zeros(max_len)\n",
        "\t\tfor i in range(0, len(text)):\n",
        "\t\t\tif i > max_len:\n",
        "\t\t\t\treturn data\n",
        "\t\t\telif text[i] in char_dict:\n",
        "\t\t\t\tdata[i] = char_dict[text[i]]\n",
        "\t\t\telse:\n",
        "\t\t\t\t# unknown character set to be 68\n",
        "\t\t\t\tdata[i] = 68\n",
        "\t\treturn data\n",
        "\n",
        "def load_csv_file(filename, num_classes):\n",
        "\t\t\"\"\"\n",
        "\t\tLoad CSV file, generate one-hot labels and process text data as Paper did.\n",
        "\t\t\"\"\"\n",
        "\t\tall_data = []\n",
        "\t\tlabels = []\n",
        "\t\twith open(filename) as f:\n",
        "\t\t\treader = csv.DictReader(f, fieldnames=['class'], restkey='fields')\n",
        "\t\t\tfor row in reader:\n",
        "\t\t\t\t# One-hot\n",
        "\t\t\t\tone_hot = np.zeros(num_classes)\n",
        "\t\t\t\tone_hot[int(row['class']) - 1] = 1\n",
        "\t\t\t\tlabels.append(one_hot)\n",
        "\t\t\t\t# Char2vec\n",
        "\t\t\t\tdata = np.ones(max_len)*68\n",
        "\t\t\t\ttext = row['fields'][-1].lower()\n",
        "\t\t\t\tall_data.append(char2vec(text))\n",
        "\t\tf.close()\n",
        "\t\treturn np.array(all_data), np.array(labels)\n",
        "  \n",
        "  \n",
        "train_data, train_label = load_csv_file(dataset_path+'train.csv', 4)\n",
        "test_data, test_label = load_csv_file(dataset_path+'test.csv', 4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOMTh0z2yEAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_data=test_data[:3800]\n",
        "val_label=test_label[:3800]\n",
        "\n",
        "test_data=test_data[3800:]\n",
        "test_lable=test_label[3800:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YakE3ncYyGyk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def just_dense(num_classes, depth=9, sequence_length=1024, embedding_dim=16, \n",
        "          shortcut=False, pool_type='max', sorted=True, use_bias=False, input_tensor=None):\n",
        "\n",
        "    inputs = Input(shape=(sequence_length, ), name='inputs')\n",
        "    embedded_chars = Embedding(input_dim=sequence_length, output_dim=embedding_dim)(inputs)\n",
        "    out = BatchNormalization()(embedded_chars)\n",
        "    out=Flatten()(out)\n",
        "    # Dense Layers\n",
        "    out = Dense(16, activation='relu')(out)\n",
        "    out=Dropout(rate=0.25)(out)\n",
        "    out = Dense(16, activation='relu')(out)\n",
        "    out=Dropout(rate=0.25)(out)\n",
        "    out = Dense(16, activation='relu')(out)\n",
        "    out=Dropout(rate=0.25)(out)\n",
        "    out = Dense(num_classes, activation='softmax')(out)\n",
        "\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = inputs\n",
        "\n",
        "    # Create model.\n",
        "    model = Model(inputs=inputs, outputs=out, name='VDCNN')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZcvi-zyy-VL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "class NBatchLogger(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    A Logger that log average performance per `display` steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, display):\n",
        "        self.step = 0\n",
        "        self.display = display\n",
        "        self.metric_cache = {}\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.step += 1\n",
        "        for k in self.params['metrics']:\n",
        "            if k in logs:\n",
        "                self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
        "        if self.step % self.display == 0:\n",
        "            metrics_log = ''\n",
        "            for (k, v) in self.metric_cache.items():\n",
        "                val = v / self.display\n",
        "                if abs(val) > 1e-3:\n",
        "                    metrics_log += ' - %s: %.4f' % (k, val)\n",
        "                else:\n",
        "                    metrics_log += ' - %s: %.4e' % (k, val)\n",
        "            print('step: {}/{} ... {}'.format(self.step,\n",
        "                                          self.params['steps'],\n",
        "                                          metrics_log))\n",
        "            self.metric_cache.clear()\n",
        "\n",
        "out_batch = NBatchLogger(display=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LII4RR-n5tfT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 60:\n",
        "        lrate = 0.000125\n",
        "    elif epoch > 40:\n",
        "        lrate = 0.00025\n",
        "    elif epoch > 20:\n",
        "        lrate = 0.0005\n",
        "    elif epoch > 10:\n",
        "        lrate = 0.00075           \n",
        "    return lrate\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "lrate = LearningRateScheduler(lr_schedule,verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gxjvx9zQXQI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "lrate = LearningRateScheduler(lr_schedule,verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-VkS-pOygDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1680
        },
        "outputId": "8af88109-8083-4d91-bc75-0322636084c9"
      },
      "cell_type": "code",
      "source": [
        "model = just_dense(num_classes=train_label.shape[1])\n",
        "opt=keras.optimizers.Adam()\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(\"/content/gdrive/My Drive/checkpoints/\"+\"weights.best_small_dense_3.hdf5\", verbose=1, monitor='val_acc',save_best_only=True, mode='auto')  \n",
        "out_batch = NBatchLogger(display=10000)\n",
        "model.fit(train_data, train_label,batch_size=32,epochs=100,callbacks=[checkpoint,lrate],validation_data=(val_data,val_label),shuffle=True,verbose=0)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.36737, saving model to /content/gdrive/My Drive/checkpoints/weights.best_small_dense_3.hdf5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.36737 to 0.41395, saving model to /content/gdrive/My Drive/checkpoints/weights.best_small_dense_3.hdf5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.41395 to 0.43342, saving model to /content/gdrive/My Drive/checkpoints/weights.best_small_dense_3.hdf5\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.43342\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.43342 to 0.45368, saving model to /content/gdrive/My Drive/checkpoints/weights.best_small_dense_3.hdf5\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.45368\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.45368 to 0.47895, saving model to /content/gdrive/My Drive/checkpoints/weights.best_small_dense_3.hdf5\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.47895\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.47895\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.47895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1389591dee14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/checkpoints/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"weights.best_small_dense_3.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNBatchLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ifDBOtaHf2Tc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Another Try"
      ]
    },
    {
      "metadata": {
        "id": "C5f9zbuJq8jL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I think that I did that embedding stuff wrong from above. Backtracking and using the Keras library to do the heavy lifting."
      ]
    },
    {
      "metadata": {
        "id": "rKl-BBKbbNov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7hntY1Y0qoJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset_path='/content/gdrive/My Drive/ag_data/'\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kcieygvYbZUV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(dataset_path+'train.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ph_rjU-K-9y4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train[1]=train[1].astype(str)\n",
        "train[2]=train[2].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cM_Af9i4_r4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "591f90a1-c11d-4f7d-f2d4-217c1e575904"
      },
      "cell_type": "code",
      "source": [
        "train[1].values"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Wall St. Bears Claw Back Into the Black (Reuters)',\n",
              "       'Carlyle Looks Toward Commercial Aerospace (Reuters)',\n",
              "       \"Oil and Economy Cloud Stocks' Outlook (Reuters)\", ...,\n",
              "       'Saban not going to Dolphins yet', \"Today's NFL games\",\n",
              "       'Nets get Carter from Raptors'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "m4tmaZTv_hhw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_col=[]\n",
        "for i in range(len(train)):\n",
        "  new_col.append(train[1].values[i]+\" \"+train[2].values[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "684YD6oVrSEi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "^used both the title and the text for classification. Idea given by Joseph Bentivegna."
      ]
    },
    {
      "metadata": {
        "id": "nFUsf8s5bmmy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "docs=np.array(new_col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L48F0DQ7by6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbf0bdba-9700-4c29-ce9e-8fef106e5a5a"
      },
      "cell_type": "code",
      "source": [
        "labels=train[0].values\n",
        "labels"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "1qQVAx0yy2a-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# integer encode the documents\n",
        "vocab_size = 50000\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r_WkJWHtefBg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_hot_labels=np.zeros((len(train),4))\n",
        "row_num=0\n",
        "for i in labels:\n",
        "  one_hot_labels[row_num,i-1]=1\n",
        "  row_num+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8oY_mb1HcOnJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_length = 1024\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3460jyajV7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(dataset_path+'test.csv',header=None)\n",
        "new_col=[]\n",
        "for i in range(len(train)):\n",
        "  new_col.append(train[1].values[i]+\" \"+train[2].values[i])\n",
        "docs=np.array(new_col)\n",
        "labels=train[0].values\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "test_one_hot_labels=np.zeros((len(train),4))\n",
        "row_num=0\n",
        "for i in labels:\n",
        "  test_one_hot_labels[row_num,i-1]=1\n",
        "  row_num+=1\n",
        "max_length = 1024\n",
        "test_padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wr9txGONjkkw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_padded_docs=test_padded_docs[3800:]\n",
        "val_one_hot_labels=test_one_hot_labels[3800:]\n",
        "\n",
        "test_padded_docs=test_padded_docs[:3800]\n",
        "test_one_hot_labels=test_one_hot_labels[:3800]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C33QdG1HcPoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "c315187f-7e43-4d41-91b2-552e33811acc"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 512, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "checkpoint = ModelCheckpoint(\"/content/gdrive/My Drive/checkpoints/\"+\"weights.best_high_space.hdf5\", verbose=1, monitor='val_acc',save_best_only=True, mode='auto')  \n",
        "# fit the model\n",
        "model.fit(padded_docs, one_hot_labels, epochs=5,validation_data=(val_padded_docs,val_one_hot_labels), verbose=0,callbacks=[checkpoint],shuffle=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 1024, 512)         25600000  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 524288)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 2097156   \n",
            "=================================================================\n",
            "Total params: 27,697,156\n",
            "Trainable params: 27,697,156\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.91263, saving model to /content/gdrive/My Drive/checkpoints/weights.best_high_space.hdf5\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.91263\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.91263\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.91263\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.91263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a84f55f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "o9hCaUI7thTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Embedding?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GOZ0zRbkwas",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ]
    },
    {
      "metadata": {
        "id": "gIYX-gBJi7u3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 512, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.load_weights(\"/content/gdrive/My Drive/checkpoints/\"+\"weights.best_high_space.hdf5\")\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWwScc6hkzbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7ae43c6c-fb9f-42ad-fa08-6d09af2e93f2"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(val_padded_docs,val_one_hot_labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3800/3800 [==============================] - 1s 201us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27163526183680486, 0.9126315790728519]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "ggAy8DTZqhIq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test "
      ]
    },
    {
      "metadata": {
        "id": "IA8XEjJgmCCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "13bae5ac-f209-4fb8-ea60-061bcf07e33d"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(test_padded_docs,test_one_hot_labels)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3800/3800 [==============================] - 1s 172us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33820385878023346, 0.901578947368421]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "9Or1goREqjY0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Discussion"
      ]
    },
    {
      "metadata": {
        "id": "_ILDKfzfrsB7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I sort of fell into the solution on its own. Below is an explanation for parameter choices.\n",
        "\n",
        "I knew that tutorials like [this](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/) were obviously meant for shorter sentences with much less unique terms than full news articles and titles, so the hashmap needed to be larger. Thus the 50,000 dimension in the one hot of the documents.\n",
        "\n",
        "The maximum length term is given by the max size of a sentence. Obviously the tutorial here has a maximum length that is way too small, thus the 1024 length. The training set maximum length is actually around 980, but I bumped it up just in case.\n",
        "\n",
        "The last parameter is the output dimension of the Embeddding. I chose 512, just because it was larger and I felt as though it was necessary. I could make this smaller, I hear other students could run this on much smaller output dimensions, but I do believe in the following philosophy:\n",
        "\n",
        "# If it ain't broke, don't fix it."
      ]
    },
    {
      "metadata": {
        "id": "R8awjKHsuL5o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}