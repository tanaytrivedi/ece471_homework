{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trivedi_hw3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tgZ6VP-_gZfk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST\n",
        "Tanay Trivedi"
      ]
    },
    {
      "metadata": {
        "id": "wptit1j1gZfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V6ro5FHegZf1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "cGNA9xGjgZf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "5971ca99-da89-49fd-baed-d884f7a0457e"
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
        "\n",
        "x_train = mnist.train.images # Returns np.array\n",
        "y_train = np.asarray(mnist.train.labels, dtype=np.int32)\n",
        "x_test = mnist.test.images # Returns np.array\n",
        "y_test = np.asarray(mnist.test.labels, dtype=np.int32)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-ab942b64aee5>:1: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9R24ERjygZgG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create validation set..."
      ]
    },
    {
      "metadata": {
        "id": "EIvj_jAKgZgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valSetSize = .1 \n",
        "valIdx = int((1-valSetSize)*len(x_train))\n",
        "\n",
        "x_val = x_train[valIdx:]\n",
        "y_val = y_train[valIdx:]\n",
        "x_train = x_train[:valIdx]\n",
        "y_train = y_train[:valIdx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLoX0YnmgZgR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Base Configuration"
      ]
    },
    {
      "metadata": {
        "id": "zsUDxAS2gZgT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn(features, labels, mode): \n",
        "  #base configuration courtesy of  https://www.tensorflow.org/tutorials/\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "\n",
        "    conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=8,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(\n",
        "      inputs=pool1,\n",
        "      filters=8,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "    \n",
        "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 8])\n",
        "    dense = tf.layers.dense(inputs=pool2_flat, units=5, activation=tf.nn.relu)\n",
        "    dropout = tf.layers.dropout(\n",
        "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "\n",
        "    predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    vs=tf.trainable_variables()\n",
        "    loss += tf.add_n([tf.nn.l2_loss(v) for v in vs]) * 0.001 #reg parameter\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "    eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CrlNPUbegZgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "6da56e95-491a-42d5-e086-14035e90d9fe"
      },
      "cell_type": "code",
      "source": [
        "config=tf.estimator.RunConfig(log_step_count_steps=1000)\n",
        "\n",
        "mnist_classifier = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn,config=config)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpSjZU_Q\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa0a75647d0>, '_model_dir': '/tmp/tmpSjZU_Q', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 1000, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "244932gegZgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1007
        },
        "outputId": "3ee6a1ba-d210-4062-e9b4-e33b9f164ea7"
      },
      "cell_type": "code",
      "source": [
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "mnist_classifier.train(\n",
        "    input_fn=train_input_fn,\n",
        "    steps=20000);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpSjZU_Q/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3174946, step = 0\n",
            "INFO:tensorflow:global_step/sec: 187.928\n",
            "INFO:tensorflow:loss = 2.113658, step = 1000 (5.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 192.626\n",
            "INFO:tensorflow:loss = 1.8529935, step = 2000 (5.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 192.207\n",
            "INFO:tensorflow:loss = 1.7988894, step = 3000 (5.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 191.27\n",
            "INFO:tensorflow:loss = 1.7133453, step = 4000 (5.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 192.233\n",
            "INFO:tensorflow:loss = 1.6835225, step = 5000 (5.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 192.486\n",
            "INFO:tensorflow:loss = 1.7454568, step = 6000 (5.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 191.369\n",
            "INFO:tensorflow:loss = 1.5840471, step = 7000 (5.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 188.075\n",
            "INFO:tensorflow:loss = 1.6431072, step = 8000 (5.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 188.895\n",
            "INFO:tensorflow:loss = 1.734856, step = 9000 (5.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 188.898\n",
            "INFO:tensorflow:loss = 1.4864857, step = 10000 (5.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 193.064\n",
            "INFO:tensorflow:loss = 1.5356969, step = 11000 (5.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 193.232\n",
            "INFO:tensorflow:loss = 1.3203592, step = 12000 (5.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.962\n",
            "INFO:tensorflow:loss = 1.7443739, step = 13000 (5.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.971\n",
            "INFO:tensorflow:loss = 1.6216863, step = 14000 (5.076 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.906\n",
            "INFO:tensorflow:loss = 1.5390207, step = 15000 (5.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.786\n",
            "INFO:tensorflow:loss = 1.410821, step = 16000 (5.073 sec)\n",
            "INFO:tensorflow:global_step/sec: 197.303\n",
            "INFO:tensorflow:loss = 1.4361368, step = 17000 (5.069 sec)\n",
            "INFO:tensorflow:global_step/sec: 197.709\n",
            "INFO:tensorflow:loss = 1.4440781, step = 18000 (5.061 sec)\n",
            "INFO:tensorflow:global_step/sec: 196.419\n",
            "INFO:tensorflow:loss = 1.3600746, step = 19000 (5.090 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpSjZU_Q/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.282877.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n5GlUE3ogZg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "OxAZ7Wh0gZg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "3c2f8a62-cf92-4488-8d5b-298b212cfed6"
      },
      "cell_type": "code",
      "source": [
        "val_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_val},\n",
        "    y=y_val,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "val_results = mnist_classifier.evaluate(input_fn=val_input_fn)\n",
        "print(val_results)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-27-00:34:11\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpSjZU_Q/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-27-00:34:12\n",
            "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.90636367, global_step = 20000, loss = 0.79667395\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/tmpSjZU_Q/model.ckpt-20000\n",
            "{'loss': 0.79667395, 'global_step': 20000, 'accuracy': 0.90636367}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LT4Qgdlmt-W9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Increase Dense Layer Size"
      ]
    },
    {
      "metadata": {
        "id": "aOs_ubFnrMtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn_1(features, labels, mode):\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "\n",
        "    conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=8,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(\n",
        "      inputs=pool1,\n",
        "      filters=8,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 8])\n",
        "    dense = tf.layers.dense(inputs=pool2_flat, units=10, activation=tf.nn.relu)\n",
        "    dropout = tf.layers.dropout(\n",
        "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "\n",
        "    predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    vs=tf.trainable_variables()\n",
        "    loss += tf.add_n([tf.nn.l2_loss(v) for v in vs]) * 0.001\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g7GbQWMSuSlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1010
        },
        "outputId": "7c0ec620-971a-4c4a-89af-98e80ba8db5c"
      },
      "cell_type": "code",
      "source": [
        "config1=tf.estimator.RunConfig(log_step_count_steps=1000)\n",
        "\n",
        "mnist_classifier1 = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn_1,config=config1)\n",
        "\n",
        "train_input_fn_1 = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "mnist_classifier1.train(\n",
        "    input_fn=train_input_fn_1,\n",
        "    steps=20000);"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpR7ZEv7\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa060962250>, '_model_dir': '/tmp/tmpR7ZEv7', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 1000, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpR7ZEv7/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.356582, step = 0\n",
            "INFO:tensorflow:global_step/sec: 179.576\n",
            "INFO:tensorflow:loss = 1.5888315, step = 1000 (5.571 sec)\n",
            "INFO:tensorflow:global_step/sec: 185.865\n",
            "INFO:tensorflow:loss = 1.4250238, step = 2000 (5.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.309\n",
            "INFO:tensorflow:loss = 1.2141637, step = 3000 (5.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 185.856\n",
            "INFO:tensorflow:loss = 0.91211295, step = 4000 (5.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.984\n",
            "INFO:tensorflow:loss = 0.9124473, step = 5000 (5.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.498\n",
            "INFO:tensorflow:loss = 0.778784, step = 6000 (5.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 187.001\n",
            "INFO:tensorflow:loss = 0.8736642, step = 7000 (5.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.585\n",
            "INFO:tensorflow:loss = 0.8723337, step = 8000 (5.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 187.354\n",
            "INFO:tensorflow:loss = 0.80967, step = 9000 (5.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.871\n",
            "INFO:tensorflow:loss = 0.7879788, step = 10000 (5.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.392\n",
            "INFO:tensorflow:loss = 0.8590537, step = 11000 (5.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.609\n",
            "INFO:tensorflow:loss = 0.74367285, step = 12000 (5.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 187.701\n",
            "INFO:tensorflow:loss = 0.73369867, step = 13000 (5.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 183.834\n",
            "INFO:tensorflow:loss = 0.79842705, step = 14000 (5.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 183.304\n",
            "INFO:tensorflow:loss = 0.62985945, step = 15000 (5.456 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.406\n",
            "INFO:tensorflow:loss = 0.9069232, step = 16000 (5.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 186.444\n",
            "INFO:tensorflow:loss = 0.69461673, step = 17000 (5.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 187.476\n",
            "INFO:tensorflow:loss = 0.5097722, step = 18000 (5.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 188.031\n",
            "INFO:tensorflow:loss = 0.51932436, step = 19000 (5.321 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpR7ZEv7/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.6183135.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ethk36A1v2UA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "ijgf9B7Iv44A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "6f4fddb7-f365-49ff-9514-c5dc5c3d02a1"
      },
      "cell_type": "code",
      "source": [
        "val_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_val},\n",
        "    y=y_val,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "val_results = mnist_classifier1.evaluate(input_fn=val_input_fn)\n",
        "print(val_results)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-27-00:37:06\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpR7ZEv7/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-27-00:37:06\n",
            "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9710909, global_step = 20000, loss = 0.16363102\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/tmpR7ZEv7/model.ckpt-20000\n",
            "{'loss': 0.16363102, 'global_step': 20000, 'accuracy': 0.9710909}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YQP2do15wLdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Increase Dense Layer Again"
      ]
    },
    {
      "metadata": {
        "id": "lp7dKU29wO4U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn_2(features, labels, mode):\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "\n",
        "    conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=8,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(\n",
        "      inputs=pool1,\n",
        "      filters=8,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 8])\n",
        "    dense = tf.layers.dense(inputs=pool2_flat, units=1000, activation=tf.nn.relu)\n",
        "    dropout = tf.layers.dropout(\n",
        "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "\n",
        "    predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    vs=tf.trainable_variables()\n",
        "    loss += tf.add_n([tf.nn.l2_loss(v) for v in vs]) * 0.001\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHlH6bOiwZxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1010
        },
        "outputId": "7c2f3d1b-4b9d-47a2-bc95-bb90dfbc93d8"
      },
      "cell_type": "code",
      "source": [
        "config2=tf.estimator.RunConfig(log_step_count_steps=1000)\n",
        "\n",
        "mnist_classifier2 = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn_2,config=config2)\n",
        "\n",
        "train_input_fn_2 = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "mnist_classifier2.train(\n",
        "    input_fn=train_input_fn_2,\n",
        "    steps=20000);"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpXZ6iTY\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa0555bfc90>, '_model_dir': '/tmp/tmpXZ6iTY', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 1000, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpXZ6iTY/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.6080902, step = 0\n",
            "INFO:tensorflow:global_step/sec: 159.153\n",
            "INFO:tensorflow:loss = 0.81350577, step = 1000 (6.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 167.398\n",
            "INFO:tensorflow:loss = 0.55603826, step = 2000 (5.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 167.551\n",
            "INFO:tensorflow:loss = 0.39424896, step = 3000 (5.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 167.203\n",
            "INFO:tensorflow:loss = 0.3953374, step = 4000 (5.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 166.828\n",
            "INFO:tensorflow:loss = 0.3755837, step = 5000 (5.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 167.823\n",
            "INFO:tensorflow:loss = 0.4232034, step = 6000 (5.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 166.245\n",
            "INFO:tensorflow:loss = 0.35087568, step = 7000 (6.010 sec)\n",
            "INFO:tensorflow:global_step/sec: 168.792\n",
            "INFO:tensorflow:loss = 0.3521068, step = 8000 (5.928 sec)\n",
            "INFO:tensorflow:global_step/sec: 172.494\n",
            "INFO:tensorflow:loss = 0.3545913, step = 9000 (5.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 172.934\n",
            "INFO:tensorflow:loss = 0.40999007, step = 10000 (5.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 173.045\n",
            "INFO:tensorflow:loss = 0.3721385, step = 11000 (5.775 sec)\n",
            "INFO:tensorflow:global_step/sec: 171.877\n",
            "INFO:tensorflow:loss = 0.3602621, step = 12000 (5.821 sec)\n",
            "INFO:tensorflow:global_step/sec: 173.403\n",
            "INFO:tensorflow:loss = 0.41085798, step = 13000 (5.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 174.638\n",
            "INFO:tensorflow:loss = 0.37876734, step = 14000 (5.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 174.519\n",
            "INFO:tensorflow:loss = 0.30585194, step = 15000 (5.734 sec)\n",
            "INFO:tensorflow:global_step/sec: 174.639\n",
            "INFO:tensorflow:loss = 0.30146453, step = 16000 (5.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 175.006\n",
            "INFO:tensorflow:loss = 0.3145508, step = 17000 (5.715 sec)\n",
            "INFO:tensorflow:global_step/sec: 174.985\n",
            "INFO:tensorflow:loss = 0.3536216, step = 18000 (5.717 sec)\n",
            "INFO:tensorflow:global_step/sec: 175.158\n",
            "INFO:tensorflow:loss = 0.30192405, step = 19000 (5.709 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpXZ6iTY/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.2909139.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Q7KdHIUxDbN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "CCtKtx_xxHIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "5d37d290-3c5e-45ff-9c75-3076c25dedf2"
      },
      "cell_type": "code",
      "source": [
        "val_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_val},\n",
        "    y=y_val,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "val_results = mnist_classifier2.evaluate(input_fn=val_input_fn)\n",
        "print(val_results)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-27-00:39:40\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpXZ6iTY/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-27-00:39:40\n",
            "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.986, global_step = 20000, loss = 0.31166527\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/tmpXZ6iTY/model.ckpt-20000\n",
            "{'loss': 0.31166527, 'global_step': 20000, 'accuracy': 0.986}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eJcfupTOgZhG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test"
      ]
    },
    {
      "metadata": {
        "id": "TjisbQedgZhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "0e242720-f6db-47c9-dc4c-a6ca4f31fcb1"
      },
      "cell_type": "code",
      "source": [
        "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x = {\"x\": x_test},\n",
        "    y=y_test,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "test_results = mnist_classifier2.evaluate(input_fn=test_input_fn)\n",
        "print(test_results)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-27-00:39:44\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpXZ6iTY/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-27-00:39:45\n",
            "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9847, global_step = 20000, loss = 0.304998\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/tmpXZ6iTY/model.ckpt-20000\n",
            "{'loss': 0.304998, 'global_step': 20000, 'accuracy': 0.9847}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uNYLfo78gZhQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}