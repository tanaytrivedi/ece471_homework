{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trivedi_hw4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tgZ6VP-_gZfk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR 10\n",
        "Tanay Trivedi"
      ]
    },
    {
      "metadata": {
        "id": "wptit1j1gZfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iY5NFFGCRyQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b9b8018-38ef-45a9-b27f-cd991b31e764"
      },
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "V6ro5FHegZf1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "do8xJVVeeMbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cf9eceaa-034c-445d-804e-4e25f27417b8"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()\n",
        "x_train=x_train.astype(\"float32\")\n",
        "y_train=y_train.astype(\"int32\")\n",
        "x_test=x_test.astype(\"float32\")\n",
        "y_test=y_test.astype(\"int32\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 96s 1us/step\n",
            "170508288/170498071 [==============================] - 96s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9R24ERjygZgG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create validation set..."
      ]
    },
    {
      "metadata": {
        "id": "EIvj_jAKgZgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valSetSize = .1 \n",
        "valIdx = int((1-valSetSize)*len(x_train))\n",
        "\n",
        "x_val = x_train[valIdx:]\n",
        "y_val = y_train[valIdx:]\n",
        "x_train = x_train[:valIdx]\n",
        "y_train = y_train[:valIdx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLoX0YnmgZgR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Base Configuration"
      ]
    },
    {
      "metadata": {
        "id": "zsUDxAS2gZgT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn_1(features, labels, mode):\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n",
        "    \n",
        "    conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=64,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "    conv1_bn = tf.layers.batch_normalization(pool1)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(\n",
        "      inputs=conv1_bn,\n",
        "      filters=128,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "    conv2_bn = tf.layers.batch_normalization(pool2)\n",
        "    \n",
        "    conv3 = tf.layers.conv2d(\n",
        "      inputs=conv2_bn,\n",
        "      filters=256,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
        "    conv3_bn = tf.layers.batch_normalization(pool3)\n",
        "    \n",
        "    \n",
        "    conv4 = tf.layers.conv2d(\n",
        "      inputs=conv3_bn,\n",
        "      filters=512,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
        "    conv4_bn = tf.layers.batch_normalization(pool4)\n",
        "\n",
        "    pool4_flat = tf.contrib.layers.flatten(conv4_bn)  \n",
        "\n",
        "    full1 = tf.layers.dense(inputs=pool4_flat, units=128, activation=tf.nn.relu)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=full1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    full1 = tf.layers.dense(inputs=full1, units=256, activation=tf.nn.relu)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=full1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    full1 = tf.layers.dense(inputs=full1, units=512, activation=tf.nn.relu)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=full1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    full1 = tf.layers.dense(inputs=full1, units=1024, activation=tf.nn.relu)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=full1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    logits = tf.layers.dense(inputs=full1, units=10)\n",
        "\n",
        "    predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    vs=tf.trainable_variables()\n",
        "    loss += tf.add_n([tf.nn.l2_loss(v) for v in vs]) * 0.001\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CrlNPUbegZgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "faaed39b-bd2d-4c33-996f-63c13e4ea3c4"
      },
      "cell_type": "code",
      "source": [
        "config=tf.estimator.RunConfig(log_step_count_steps=1000)\n",
        "\n",
        "mnist_classifier = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn_1,config=config)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpLx292d\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5d6b2558d0>, '_model_dir': '/tmp/tmpLx292d', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 1000, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "244932gegZgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "7d3de351-d2d2-4559-9612-3e58bcf2d337"
      },
      "cell_type": "code",
      "source": [
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train,\n",
        "    batch_size=128,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "mnist_classifier.train(\n",
        "    input_fn=train_input_fn,\n",
        "    steps=10000);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpLx292d/model.ckpt.\n",
            "INFO:tensorflow:loss = 11.235537, step = 0\n",
            "INFO:tensorflow:global_step/sec: 13.9994\n",
            "INFO:tensorflow:loss = 4.734158, step = 1000 (71.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.0798\n",
            "INFO:tensorflow:loss = 4.521372, step = 2000 (71.025 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.1106\n",
            "INFO:tensorflow:loss = 4.559145, step = 3000 (70.871 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.0968\n",
            "INFO:tensorflow:loss = 4.3638554, step = 4000 (70.935 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.1079\n",
            "INFO:tensorflow:loss = 4.380804, step = 5000 (70.883 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.0931\n",
            "INFO:tensorflow:loss = 4.2947364, step = 6000 (70.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.1145\n",
            "INFO:tensorflow:loss = 4.288974, step = 7000 (70.852 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.1024\n",
            "INFO:tensorflow:loss = 4.159645, step = 8000 (70.910 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8441 into /tmp/tmpLx292d/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 14.0554\n",
            "INFO:tensorflow:loss = 4.0749407, step = 9000 (71.145 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpLx292d/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 4.0791926.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n5GlUE3ogZg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "OxAZ7Wh0gZg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "41782d57-e108-448f-da21-720066e93d5b"
      },
      "cell_type": "code",
      "source": [
        "val_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_val},\n",
        "    y=y_val,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "val_results = mnist_classifier.evaluate(input_fn=val_input_fn)\n",
        "print(val_results)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-01-23:10:45\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpLx292d/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-01-23:10:46\n",
            "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.3824, global_step = 10000, loss = 4.0393972\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmpLx292d/model.ckpt-10000\n",
            "{'loss': 4.0393972, 'global_step': 10000, 'accuracy': 0.3824}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LT4Qgdlmt-W9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Remove L2 Reg"
      ]
    },
    {
      "metadata": {
        "id": "aOs_ubFnrMtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn_2(features, labels, mode):\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n",
        "    \n",
        "    conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=64,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "    conv1_bn = tf.layers.batch_normalization(pool1)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(\n",
        "      inputs=conv1_bn,\n",
        "      filters=128,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "    conv2_bn = tf.layers.batch_normalization(pool2)\n",
        "    \n",
        "    conv3 = tf.layers.conv2d(\n",
        "      inputs=conv2_bn,\n",
        "      filters=256,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
        "    conv3_bn = tf.layers.batch_normalization(pool3)\n",
        "    \n",
        "    \n",
        "    conv4 = tf.layers.conv2d(\n",
        "      inputs=conv3_bn,\n",
        "      filters=512,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
        "    conv4_bn = tf.layers.batch_normalization(pool4)\n",
        "\n",
        "    pool4_flat = tf.contrib.layers.flatten(conv4_bn)  \n",
        "\n",
        "    full1 = tf.layers.dense(inputs=pool4_flat, units=128, activation=tf.nn.relu)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=full1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    full1 = tf.layers.dense(inputs=full1, units=256, activation=tf.nn.relu)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=full1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    full1 = tf.layers.dense(inputs=full1, units=512, activation=tf.nn.relu)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=full1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    full1 = tf.layers.dense(inputs=full1, units=1024, activation=tf.nn.relu)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=full1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    full1 = tf.layers.batch_normalization(full1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    logits = tf.layers.dense(inputs=full1, units=10)\n",
        "\n",
        "    predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    #vs=tf.trainable_variables()\n",
        "    #loss += tf.add_n([tf.nn.l2_loss(v) for v in vs]) * 0.001\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g7GbQWMSuSlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "8b93b746-155e-49ce-e497-e58600bb76b4"
      },
      "cell_type": "code",
      "source": [
        "config1=tf.estimator.RunConfig(log_step_count_steps=1000)\n",
        "\n",
        "mnist_classifier1 = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn_2,config=config1)\n",
        "\n",
        "train_input_fn_1 = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train,\n",
        "    batch_size=128,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "mnist_classifier1.train(\n",
        "    input_fn=train_input_fn_1,\n",
        "    steps=10000);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpMVVUkV\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01d97f0890>, '_model_dir': '/tmp/tmpMVVUkV', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 1000, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpMVVUkV/model.ckpt.\n",
            "INFO:tensorflow:loss = 6.990841, step = 0\n",
            "INFO:tensorflow:global_step/sec: 14.4289\n",
            "INFO:tensorflow:loss = 1.9200916, step = 1000 (69.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.5646\n",
            "INFO:tensorflow:loss = 1.8687003, step = 2000 (68.660 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.4907\n",
            "INFO:tensorflow:loss = 1.5511101, step = 3000 (69.013 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.5028\n",
            "INFO:tensorflow:loss = 1.6523418, step = 4000 (68.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.5185\n",
            "INFO:tensorflow:loss = 1.4939599, step = 5000 (68.878 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.4735\n",
            "INFO:tensorflow:loss = 1.397447, step = 6000 (69.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.5224\n",
            "INFO:tensorflow:loss = 1.2367251, step = 7000 (68.864 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.454\n",
            "INFO:tensorflow:loss = 1.1389633, step = 8000 (69.182 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8677 into /tmp/tmpMVVUkV/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 14.4641\n",
            "INFO:tensorflow:loss = 1.2911698, step = 9000 (69.137 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpMVVUkV/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.113972.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ethk36A1v2UA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "ijgf9B7Iv44A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "f6e89376-25a3-4178-96cd-dbc3f9eeb47b"
      },
      "cell_type": "code",
      "source": [
        "val_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_val},\n",
        "    y=y_val,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "val_results = mnist_classifier1.evaluate(input_fn=val_input_fn)\n",
        "print(val_results)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-01-23:37:56\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpMVVUkV/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-01-23:37:58\n",
            "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.543, global_step = 10000, loss = 1.3303111\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmpMVVUkV/model.ckpt-10000\n",
            "{'loss': 1.3303111, 'global_step': 10000, 'accuracy': 0.543}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YQP2do15wLdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Change Up Config"
      ]
    },
    {
      "metadata": {
        "id": "lp7dKU29wO4U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn_3(features, labels, mode):\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n",
        "    \n",
        "    conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=32,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    \n",
        "    conv1_bn = tf.layers.batch_normalization(conv1)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(\n",
        "      inputs=conv1_bn,\n",
        "      filters=32,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #\n",
        "    conv2_bn = tf.layers.batch_normalization(conv2)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2_bn, pool_size=[4, 4], strides=2)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=pool2, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    conv3 = tf.layers.conv2d(\n",
        "      inputs=full1,\n",
        "      filters=64,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
        "    conv3_bn = tf.layers.batch_normalization(conv3)\n",
        "    \n",
        "    \n",
        "    conv4 = tf.layers.conv2d(\n",
        "      inputs=conv3_bn,\n",
        "      filters=64,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #\n",
        "    conv4_bn = tf.layers.batch_normalization(conv4)\n",
        "    pool4 = tf.layers.max_pooling2d(inputs=conv4_bn, pool_size=[4, 4], strides=2)\n",
        "    full2 = tf.layers.dropout(\n",
        "      inputs=pool4, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    pool4_flat = tf.contrib.layers.flatten(full2)  \n",
        "\n",
        "    \"\"\"full3 = tf.layers.dense(inputs=pool4_flat, units=256, activation=tf.nn.relu)\n",
        "    full4 = tf.layers.dropout(\n",
        "      inputs=full3, rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\"\"\"\n",
        "    \n",
        "    full5 = tf.layers.dense(inputs=pool4_flat, units=512, activation=tf.nn.relu)\n",
        "    full6 = tf.layers.dropout(\n",
        "      inputs=full5, rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    logits = tf.layers.dense(inputs=full6, units=10)\n",
        "\n",
        "    predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHlH6bOiwZxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1006
        },
        "outputId": "023b67dd-5730-4784-e20b-5af3ecfbb205"
      },
      "cell_type": "code",
      "source": [
        "config2=tf.estimator.RunConfig(log_step_count_steps=1000)\n",
        "\n",
        "mnist_classifier2 = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn_3,config=config2)\n",
        "\n",
        "train_input_fn_2 = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train,\n",
        "    batch_size=128,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "mnist_classifier2.train(\n",
        "    input_fn=train_input_fn_2,\n",
        "    steps=20000);"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpX5qHeS\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c77148a90>, '_model_dir': '/tmp/tmpX5qHeS', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 1000, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpX5qHeS/model.ckpt.\n",
            "INFO:tensorflow:loss = 69.70364, step = 0\n",
            "INFO:tensorflow:global_step/sec: 19.8233\n",
            "INFO:tensorflow:loss = 1.7748091, step = 1000 (50.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.7932\n",
            "INFO:tensorflow:loss = 1.5510226, step = 2000 (50.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.9537\n",
            "INFO:tensorflow:loss = 1.4369545, step = 3000 (50.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.0221\n",
            "INFO:tensorflow:loss = 1.1387804, step = 4000 (49.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.8883\n",
            "INFO:tensorflow:loss = 1.1702038, step = 5000 (50.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.8264\n",
            "INFO:tensorflow:loss = 0.92749095, step = 6000 (50.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.0227\n",
            "INFO:tensorflow:loss = 1.0852072, step = 7000 (49.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.0651\n",
            "INFO:tensorflow:loss = 0.96335053, step = 8000 (49.840 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.0701\n",
            "INFO:tensorflow:loss = 0.76152885, step = 9000 (49.825 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.8817\n",
            "INFO:tensorflow:loss = 0.6926974, step = 10000 (50.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.9835\n",
            "INFO:tensorflow:loss = 0.52495575, step = 11000 (50.044 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 11955 into /tmp/tmpX5qHeS/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 19.7951\n",
            "INFO:tensorflow:loss = 0.58067447, step = 12000 (50.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.7034\n",
            "INFO:tensorflow:loss = 0.5686699, step = 13000 (50.749 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.9008\n",
            "INFO:tensorflow:loss = 0.5409155, step = 14000 (50.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.9888\n",
            "INFO:tensorflow:loss = 0.5258372, step = 15000 (50.029 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.8484\n",
            "INFO:tensorflow:loss = 0.49135232, step = 16000 (50.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.8252\n",
            "INFO:tensorflow:loss = 0.36936927, step = 17000 (50.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.8005\n",
            "INFO:tensorflow:loss = 0.4329546, step = 18000 (50.501 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.8196\n",
            "INFO:tensorflow:loss = 0.360018, step = 19000 (50.458 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpX5qHeS/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.33921275.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Q7KdHIUxDbN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "CCtKtx_xxHIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5d767e03-1648-41d8-8b66-264035dcd542"
      },
      "cell_type": "code",
      "source": [
        "val_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_val},\n",
        "    y=y_val,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "val_results = mnist_classifier2.evaluate(input_fn=val_input_fn)\n",
        "print(val_results)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-03-03:29:53\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpX5qHeS/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-03-03:29:54\n",
            "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.7556, global_step = 20000, loss = 0.8347336\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/tmpX5qHeS/model.ckpt-20000\n",
            "{'loss': 0.8347336, 'global_step': 20000, 'accuracy': 0.7556}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O0V3jXCpMc-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## More Conv!"
      ]
    },
    {
      "metadata": {
        "id": "3RapERnNMakP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn_4(features, labels, mode):\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n",
        "    \n",
        "    conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=32,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    \n",
        "    conv1_bn = tf.layers.batch_normalization(conv1)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(\n",
        "      inputs=conv1_bn,\n",
        "      filters=32,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #\n",
        "    conv2_bn = tf.layers.batch_normalization(conv2)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2_bn, pool_size=[4, 4], strides=2)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=pool2, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    conv3 = tf.layers.conv2d(\n",
        "      inputs=full1,\n",
        "      filters=64,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
        "    conv3_bn = tf.layers.batch_normalization(conv3)\n",
        "    \n",
        "    \n",
        "    conv4 = tf.layers.conv2d(\n",
        "      inputs=conv3_bn,\n",
        "      filters=64,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #\n",
        "    conv4_bn = tf.layers.batch_normalization(conv4)\n",
        "    pool4 = tf.layers.max_pooling2d(inputs=conv4_bn, pool_size=[4, 4], strides=2)\n",
        "    full2 = tf.layers.dropout(\n",
        "      inputs=pool4, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    conv3 = tf.layers.conv2d(\n",
        "      inputs=full2,\n",
        "      filters=128,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
        "    conv3_bn = tf.layers.batch_normalization(conv3)\n",
        "    \n",
        "    \n",
        "    conv5 = tf.layers.conv2d(\n",
        "      inputs=conv3_bn,\n",
        "      filters=128,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #\n",
        "    conv5_bn = tf.layers.batch_normalization(conv5)\n",
        "    pool5 = tf.layers.max_pooling2d(inputs=conv5_bn, pool_size=[4, 4], strides=2)\n",
        "    full7 = tf.layers.dropout(\n",
        "      inputs=pool5, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    pool4_flat = tf.contrib.layers.flatten(full7)  \n",
        "\n",
        "    \"\"\"full3 = tf.layers.dense(inputs=pool4_flat, units=256, activation=tf.nn.relu)\n",
        "    full4 = tf.layers.dropout(\n",
        "      inputs=full3, rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\"\"\"\n",
        "    \n",
        "    full5 = tf.layers.dense(inputs=pool4_flat, units=512, activation=tf.nn.relu)\n",
        "    full6 = tf.layers.dropout(\n",
        "      inputs=full5, rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    logits = tf.layers.dense(inputs=full6, units=10)\n",
        "\n",
        "    predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SX6MhO-ZMakm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1023
        },
        "outputId": "f857b267-eba2-4979-9880-039394ffef02"
      },
      "cell_type": "code",
      "source": [
        "config2=tf.estimator.RunConfig(log_step_count_steps=1000)\n",
        "\n",
        "mnist_classifier2 = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn_4,config=config2)\n",
        "\n",
        "train_input_fn_2 = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train,\n",
        "    batch_size=128,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "mnist_classifier2.train(\n",
        "    input_fn=train_input_fn_2,\n",
        "    steps=20000);"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpQY9IBZ\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c7b094790>, '_model_dir': '/tmp/tmpQY9IBZ', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 1000, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpQY9IBZ/model.ckpt.\n",
            "INFO:tensorflow:loss = 29.207798, step = 0\n",
            "INFO:tensorflow:global_step/sec: 15.5724\n",
            "INFO:tensorflow:loss = 1.4767143, step = 1000 (64.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6865\n",
            "INFO:tensorflow:loss = 1.2176355, step = 2000 (63.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6778\n",
            "INFO:tensorflow:loss = 0.9689957, step = 3000 (63.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.7014\n",
            "INFO:tensorflow:loss = 0.64732903, step = 4000 (63.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6875\n",
            "INFO:tensorflow:loss = 0.68923306, step = 5000 (63.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6829\n",
            "INFO:tensorflow:loss = 0.6831591, step = 6000 (63.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.7097\n",
            "INFO:tensorflow:loss = 0.5640446, step = 7000 (63.657 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6777\n",
            "INFO:tensorflow:loss = 0.6834424, step = 8000 (63.785 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.7017\n",
            "INFO:tensorflow:loss = 0.43081227, step = 9000 (63.688 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9402 into /tmp/tmpQY9IBZ/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 15.6338\n",
            "INFO:tensorflow:loss = 0.46530068, step = 10000 (63.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6821\n",
            "INFO:tensorflow:loss = 0.49099424, step = 11000 (63.767 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6841\n",
            "INFO:tensorflow:loss = 0.29155958, step = 12000 (63.759 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.682\n",
            "INFO:tensorflow:loss = 0.33327731, step = 13000 (63.767 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6717\n",
            "INFO:tensorflow:loss = 0.31453785, step = 14000 (63.807 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6877\n",
            "INFO:tensorflow:loss = 0.23132077, step = 15000 (63.747 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.673\n",
            "INFO:tensorflow:loss = 0.16938248, step = 16000 (63.804 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.6875\n",
            "INFO:tensorflow:loss = 0.4381398, step = 17000 (63.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.685\n",
            "INFO:tensorflow:loss = 0.22175921, step = 18000 (63.757 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 18809 into /tmp/tmpQY9IBZ/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 15.6517\n",
            "INFO:tensorflow:loss = 0.1913315, step = 19000 (63.890 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpQY9IBZ/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.06623254.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RD2QDQAnMak2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "ziZiI1g0Mak5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "199139cf-ad9d-4cbb-8eb7-139791c0946e"
      },
      "cell_type": "code",
      "source": [
        "val_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_val},\n",
        "    y=y_val,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "val_results = mnist_classifier2.evaluate(input_fn=val_input_fn)\n",
        "print(val_results)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-03-03:53:01\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpQY9IBZ/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-03-03:53:02\n",
            "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.7628, global_step = 20000, loss = 1.0546504\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/tmpQY9IBZ/model.ckpt-20000\n",
            "{'loss': 1.0546504, 'global_step': 20000, 'accuracy': 0.7628}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vDoA0mmmQAEd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## More Dense!"
      ]
    },
    {
      "metadata": {
        "id": "Z5vMZLexQAEk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn_5(features, labels, mode):\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n",
        "    \n",
        "    conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=32,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    \n",
        "    conv1_bn = tf.layers.batch_normalization(conv1)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(\n",
        "      inputs=conv1_bn,\n",
        "      filters=32,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #\n",
        "    conv2_bn = tf.layers.batch_normalization(conv2)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2_bn, pool_size=[4, 4], strides=2)\n",
        "    full1 = tf.layers.dropout(\n",
        "      inputs=pool2, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    conv3 = tf.layers.conv2d(\n",
        "      inputs=full1,\n",
        "      filters=64,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
        "    conv3_bn = tf.layers.batch_normalization(conv3)\n",
        "    \n",
        "    \n",
        "    conv4 = tf.layers.conv2d(\n",
        "      inputs=conv3_bn,\n",
        "      filters=64,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #\n",
        "    conv4_bn = tf.layers.batch_normalization(conv4)\n",
        "    pool4 = tf.layers.max_pooling2d(inputs=conv4_bn, pool_size=[4, 4], strides=2)\n",
        "    full2 = tf.layers.dropout(\n",
        "      inputs=pool4, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    conv3 = tf.layers.conv2d(\n",
        "      inputs=full2,\n",
        "      filters=128,\n",
        "      kernel_size=[8, 8],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
        "    conv3_bn = tf.layers.batch_normalization(conv3)\n",
        "    \n",
        "    \n",
        "    conv5 = tf.layers.conv2d(\n",
        "      inputs=conv3_bn,\n",
        "      filters=128,\n",
        "      kernel_size=[4, 4],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu)\n",
        "    #\n",
        "    conv5_bn = tf.layers.batch_normalization(conv5)\n",
        "    pool5 = tf.layers.max_pooling2d(inputs=conv5_bn, pool_size=[4, 4], strides=2)\n",
        "    full7 = tf.layers.dropout(\n",
        "      inputs=pool5, rate=0.25, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    pool4_flat = tf.contrib.layers.flatten(full7)  \n",
        "\n",
        "    full3 = tf.layers.dense(inputs=pool4_flat, units=256, activation=tf.nn.relu)\n",
        "    full4 = tf.layers.dropout(\n",
        "      inputs=full3, rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    full5 = tf.layers.dense(inputs=full4, units=512, activation=tf.nn.relu)\n",
        "    full6 = tf.layers.dropout(\n",
        "      inputs=full5, rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    \n",
        "    logits = tf.layers.dense(inputs=full6, units=10)\n",
        "\n",
        "    predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBUbYdGYQAEu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1023
        },
        "outputId": "8a21aabd-42af-41e5-a05b-b7f951406e0e"
      },
      "cell_type": "code",
      "source": [
        "config2=tf.estimator.RunConfig(log_step_count_steps=1000)\n",
        "\n",
        "mnist_classifier2 = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn_5,config=config2)\n",
        "\n",
        "train_input_fn_2 = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_train},\n",
        "    y=y_train,\n",
        "    batch_size=128,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "mnist_classifier2.train(\n",
        "    input_fn=train_input_fn_2,\n",
        "    steps=20000);"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqc_O5R\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c6d237590>, '_model_dir': '/tmp/tmpqc_O5R', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 1000, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpqc_O5R/model.ckpt.\n",
            "INFO:tensorflow:loss = 26.94197, step = 0\n",
            "INFO:tensorflow:global_step/sec: 15.2253\n",
            "INFO:tensorflow:loss = 1.5834019, step = 1000 (65.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.3107\n",
            "INFO:tensorflow:loss = 1.2877679, step = 2000 (65.314 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.2913\n",
            "INFO:tensorflow:loss = 1.1366822, step = 3000 (65.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.2384\n",
            "INFO:tensorflow:loss = 1.1121061, step = 4000 (65.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.3757\n",
            "INFO:tensorflow:loss = 0.9488986, step = 5000 (65.042 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.3542\n",
            "INFO:tensorflow:loss = 0.87711555, step = 6000 (65.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.3868\n",
            "INFO:tensorflow:loss = 0.72295123, step = 7000 (64.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.176\n",
            "INFO:tensorflow:loss = 0.69922775, step = 8000 (65.896 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.0628\n",
            "INFO:tensorflow:loss = 0.6075649, step = 9000 (66.391 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9157 into /tmp/tmpqc_O5R/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 15.0896\n",
            "INFO:tensorflow:loss = 0.29583126, step = 10000 (66.268 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.0371\n",
            "INFO:tensorflow:loss = 0.4723301, step = 11000 (66.505 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.072\n",
            "INFO:tensorflow:loss = 0.5750865, step = 12000 (66.348 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.9843\n",
            "INFO:tensorflow:loss = 0.28433797, step = 13000 (66.733 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.2194\n",
            "INFO:tensorflow:loss = 0.3724701, step = 14000 (65.706 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.25\n",
            "INFO:tensorflow:loss = 0.3390212, step = 15000 (65.578 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.41\n",
            "INFO:tensorflow:loss = 0.28690025, step = 16000 (64.890 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.258\n",
            "INFO:tensorflow:loss = 0.31149507, step = 17000 (65.543 sec)\n",
            "INFO:tensorflow:global_step/sec: 15.3876\n",
            "INFO:tensorflow:loss = 0.21980715, step = 18000 (64.987 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 18275 into /tmp/tmpqc_O5R/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 15.2935\n",
            "INFO:tensorflow:loss = 0.1916044, step = 19000 (65.383 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpqc_O5R/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.12565815.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X7ljxOr4QAE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "EinRZDNbQAFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f7c5426e-84e5-4b9e-d1be-ce278a8e2e61"
      },
      "cell_type": "code",
      "source": [
        "val_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": x_val},\n",
        "    y=y_val,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "val_results = mnist_classifier2.evaluate(input_fn=val_input_fn)\n",
        "print(val_results)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-03-04:16:54\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpqc_O5R/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-03-04:16:56\n",
            "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.7668, global_step = 20000, loss = 0.94575536\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/tmpqc_O5R/model.ckpt-20000\n",
            "{'loss': 0.94575536, 'global_step': 20000, 'accuracy': 0.7668}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nU4ienaZSBVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras Version! w/ Learning Rate Decay"
      ]
    },
    {
      "metadata": {
        "id": "0ueLxDL4t1Br",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "def lr_schedule(epoch):          \n",
        "    return 0.001*np.exp(-0.02*epoch)\n",
        "lr=LearningRateScheduler(lr_schedule,verbose=0)\n",
        "#inspired by Jacob Maareks implementation, but i customized a smooth function rather than his step function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLnTak5wSBV1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential()\n",
        "#conv layer 1\n",
        "model.add(keras.layers.Conv2D(32,(8,8),padding=\"same\",input_shape=x_train.shape[1:]))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(32,(4,4)))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(4,4),strides=2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "#conv layer 2\n",
        "model.add(keras.layers.Conv2D(64,(8,8),padding=\"same\"))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(64,(4,4)))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(4,4),strides=2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "#dense layer\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(512))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(10)) # 10 labels\n",
        "model.add(keras.layers.Activation(\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPTnayLjW9si",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NBatchLogger(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    A Logger that log average performance per `display` steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, display):\n",
        "        self.step = 0\n",
        "        self.display = display\n",
        "        self.metric_cache = {}\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.step += 1\n",
        "        for k in self.params['metrics']:\n",
        "            if k in logs:\n",
        "                self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
        "        if self.step % self.display == 0:\n",
        "            metrics_log = ''\n",
        "            for (k, v) in self.metric_cache.items():\n",
        "                val = v / self.display\n",
        "                if abs(val) > 1e-3:\n",
        "                    metrics_log += ' - %s: %.4f' % (k, val)\n",
        "                else:\n",
        "                    metrics_log += ' - %s: %.4e' % (k, val)\n",
        "            print('step: {}/{} ... {}'.format(self.step,\n",
        "                                          self.params['steps'],\n",
        "                                          metrics_log))\n",
        "            self.metric_cache.clear()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dUZlr4vPX3hM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_k=keras.utils.np_utils.to_categorical(y_train)\n",
        "y_val_k=keras.utils.np_utils.to_categorical(y_val)\n",
        "y_test_k=keras.utils.np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hDU5zkrlSBV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b3861b35-4d0d-4445-dda8-8603aed32957"
      },
      "cell_type": "code",
      "source": [
        "out_batch = NBatchLogger(display=10000)\n",
        "model.fit(x=x_train, y=y_train_k, batch_size=100, epochs=75, verbose=0, callbacks=[out_batch,lr], validation_data=(x_val,y_val_k), shuffle=True)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 10000/None ...  - acc: 0.7450 - loss: 0.7325\n",
            "step: 20000/None ...  - acc: 0.9039 - loss: 0.2730\n",
            "step: 30000/None ...  - acc: 0.9457 - loss: 0.1553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b220cd690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "wKZ8qI96lgSX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation 75epochs"
      ]
    },
    {
      "metadata": {
        "id": "vFMwpDPJlgSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PREDICTED_CLASSES = model.predict_classes(x_val, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_r16d8XYlgSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "526a7e40-c680-4e54-e145-c37a3b6f8a83"
      },
      "cell_type": "code",
      "source": [
        "temp = sum(y_val[:,0] == PREDICTED_CLASSES)\n",
        "temp/float(len(y_val[:,0]))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "XBVrPNwISBV8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation 100 epochs"
      ]
    },
    {
      "metadata": {
        "id": "RXw8LZ4HSBV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PREDICTED_CLASSES = model.predict_classes(x_val, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5IhJ8a_iMJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c55cea14-8ca2-49f7-df8d-ffba7a8ea819"
      },
      "cell_type": "code",
      "source": [
        "temp = sum(y_val[:,0] == PREDICTED_CLASSES)\n",
        "temp/float(len(y_val[:,0]))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8238"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "Y0L3_EkxjkWa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation 125 epochs"
      ]
    },
    {
      "metadata": {
        "id": "N3iA4E6hjkWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PREDICTED_CLASSES = model.predict_classes(x_val, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9AYtS0njkWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a52483fc-780b-4b39-f0fe-86e2f511ad81"
      },
      "cell_type": "code",
      "source": [
        "temp = sum(y_val[:,0] == PREDICTED_CLASSES)\n",
        "temp/float(len(y_val[:,0]))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8044"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "JdIAVKUwi7-z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras more dense\n"
      ]
    },
    {
      "metadata": {
        "id": "R-cEGPNMi-46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential()\n",
        "#conv layer 1\n",
        "model.add(keras.layers.Conv2D(32,(8,8),padding=\"same\",input_shape=x_train.shape[1:]))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(32,(4,4)))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(4,4),strides=2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "#conv layer 2\n",
        "model.add(keras.layers.Conv2D(64,(8,8),padding=\"same\"))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(64,(4,4)))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(4,4),strides=2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "#conv layer 3\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(512))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(1024))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(10))\n",
        "model.add(keras.layers.Activation(\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HAD-6NaqjTfH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "642410fd-caaf-446e-ffd5-8550d4b973f2"
      },
      "cell_type": "code",
      "source": [
        "out_batch = NBatchLogger(display=10000)\n",
        "model.fit(x=x_train, y=y_train_k, batch_size=100, epochs=100, verbose=0, callbacks=[out_batch], validation_data=(x_val,y_val_k), shuffle=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 10000/None ...  - acc: 0.7255 - loss: 0.7977\n",
            "step: 20000/None ...  - acc: 0.8746 - loss: 0.3667\n",
            "step: 30000/None ...  - acc: 0.9178 - loss: 0.2414\n",
            "step: 40000/None ...  - acc: 0.9381 - loss: 0.1842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b2c450950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "5z-4MqvujctC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "tEXCRCLOjctF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PREDICTED_CLASSES = model.predict_classes(x_val, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpZSzn_MjUjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bceeec8f-0d48-4260-e8a9-02791c31cbc4"
      },
      "cell_type": "code",
      "source": [
        "temp = sum(y_val[:,0] == PREDICTED_CLASSES)\n",
        "temp/float(len(y_val[:,0]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "cvqZZ0v0thSm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras deep and lr\n"
      ]
    },
    {
      "metadata": {
        "id": "oWfWujGitpbw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rbmKjEAithSo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential()\n",
        "#conv layer 1\n",
        "model.add(keras.layers.Conv2D(64,(8,8),padding=\"same\",input_shape=x_train.shape[1:]))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(64,(4,4)))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(4,4),strides=2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "#conv layer 2\n",
        "model.add(keras.layers.Conv2D(128,(8,8),padding=\"same\"))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(128,(4,4)))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(8,8),strides=2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "#conv layer 3\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(1024))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(10))\n",
        "model.add(keras.layers.Activation(\"softmax\"))\n",
        "\n",
        "opt=Adam()\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LgrAOhaFthSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "67fcc4d3-2c39-4c45-f99b-4cdc2f080542"
      },
      "cell_type": "code",
      "source": [
        "out_batch = NBatchLogger(display=1000)\n",
        "model.fit(x=x_train, y=y_train_k, batch_size=100, epochs=100, verbose=0, callbacks=[out_batch,lr], validation_data=(x_val,y_val_k), shuffle=True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 24000/None ...  - acc: 0.9658 - loss: 0.1748\n",
            "step: 25000/None ...  - acc: 0.9659 - loss: 0.1847\n",
            "step: 26000/None ...  - acc: 0.9691 - loss: 0.1661\n",
            "step: 27000/None ...  - acc: 0.9717 - loss: 0.1578\n",
            "step: 28000/None ...  - acc: 0.9738 - loss: 0.1489\n",
            "step: 29000/None ...  - acc: 0.9735 - loss: 0.1530\n",
            "step: 30000/None ...  - acc: 0.9763 - loss: 0.1394\n",
            "step: 31000/None ...  - acc: 0.9784 - loss: 0.1358\n",
            "step: 32000/None ...  - acc: 0.9776 - loss: 0.1413\n",
            "step: 33000/None ...  - acc: 0.9755 - loss: 0.1465\n",
            "step: 34000/None ...  - acc: 0.9780 - loss: 0.1383\n",
            "step: 35000/None ...  - acc: 0.9806 - loss: 0.1288\n",
            "step: 36000/None ...  - acc: 0.9815 - loss: 0.1258\n",
            "step: 37000/None ...  - acc: 0.9832 - loss: 0.1159\n",
            "step: 38000/None ...  - acc: 0.9803 - loss: 0.1260\n",
            "step: 39000/None ...  - acc: 0.9801 - loss: 0.1283\n",
            "step: 40000/None ...  - acc: 0.9831 - loss: 0.1170\n",
            "step: 41000/None ...  - acc: 0.9827 - loss: 0.1203\n",
            "step: 42000/None ...  - acc: 0.9857 - loss: 0.1067\n",
            "step: 43000/None ...  - acc: 0.9852 - loss: 0.1126\n",
            "step: 44000/None ...  - acc: 0.9851 - loss: 0.1081\n",
            "step: 45000/None ...  - acc: 0.9850 - loss: 0.1169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b254bfad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "kqGE77vithSw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ]
    },
    {
      "metadata": {
        "id": "drw27NR8thSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PREDICTED_CLASSES = model.predict_classes(x_val, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zimd2QBtthSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26b3e4b4-a5d2-4525-bf71-b65dd6cced2c"
      },
      "cell_type": "code",
      "source": [
        "temp = sum(y_val[:,0] == PREDICTED_CLASSES)\n",
        "temp/float(len(y_val[:,0]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.817"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "eJcfupTOgZhG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test"
      ]
    },
    {
      "metadata": {
        "id": "uNYLfo78gZhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4544feec-b28b-4fcb-961d-4a0939b84bbd"
      },
      "cell_type": "code",
      "source": [
        "PREDICTED_CLASSES = model.predict_classes(x_test, verbose=0)\n",
        "temp = sum(y_test[:,0] == PREDICTED_CLASSES)\n",
        "temp/float(len(y_test[:,0]))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8066"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "4d8qQGKWq7c9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR 100"
      ]
    },
    {
      "metadata": {
        "id": "BywCMPp1rj-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "446da533-8a7b-457c-f2eb-dbce21df362c"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar100.load_data()\n",
        "x_train=x_train.astype(\"float32\")\n",
        "y_train=y_train.astype(\"int32\")\n",
        "x_test=x_test.astype(\"float32\")\n",
        "y_test=y_test.astype(\"int32\")\n",
        "\n",
        "valSetSize = .1 \n",
        "valIdx = int((1-valSetSize)*len(x_train))\n",
        "\n",
        "x_val = x_train[valIdx:]\n",
        "y_val = y_train[valIdx:]\n",
        "x_train = x_train[:valIdx]\n",
        "y_train = y_train[:valIdx]\n",
        "\n",
        "y_train_k=keras.utils.np_utils.to_categorical(y_train)\n",
        "y_val_k=keras.utils.np_utils.to_categorical(y_val)\n",
        "y_test_k=keras.utils.np_utils.to_categorical(y_test)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 50s 0us/step\n",
            "169017344/169001437 [==============================] - 50s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fNg9gkUKrHvx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Same Model"
      ]
    },
    {
      "metadata": {
        "id": "IAbq23_HrLwN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential()\n",
        "#conv layer 1\n",
        "model.add(keras.layers.Conv2D(32,(8,8),padding=\"same\",input_shape=x_train.shape[1:]))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(32,(4,4)))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(4,4),strides=2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "#conv layer 2\n",
        "model.add(keras.layers.Conv2D(64,(8,8),padding=\"same\"))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(64,(4,4)))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(4,4),strides=2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "#conv layer 3\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(512))\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(100)) #fine label\n",
        "model.add(keras.layers.Activation(\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\",\"top_k_categorical_accuracy\"])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5TZQayWrjCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "bade254a-c04b-4a41-d2f3-8da7e3297f67"
      },
      "cell_type": "code",
      "source": [
        "out_batch = NBatchLogger(display=1000)\n",
        "model.fit(x=x_train, y=y_train_k, batch_size=100, epochs=100, verbose=0, callbacks=[out_batch], validation_data=(x_val,y_val_k), shuffle=True)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 1000/None ...  - acc: 0.1122 - loss: 3.8975 - top_k_categorical_accuracy: 0.3169\n",
            "step: 2000/None ...  - acc: 0.2289 - loss: 3.1407 - top_k_categorical_accuracy: 0.5212\n",
            "step: 3000/None ...  - acc: 0.2994 - loss: 2.7726 - top_k_categorical_accuracy: 0.6144\n",
            "step: 4000/None ...  - acc: 0.3530 - loss: 2.5048 - top_k_categorical_accuracy: 0.6727\n",
            "step: 5000/None ...  - acc: 0.3919 - loss: 2.3194 - top_k_categorical_accuracy: 0.7119\n",
            "step: 6000/None ...  - acc: 0.4213 - loss: 2.1872 - top_k_categorical_accuracy: 0.7407\n",
            "step: 7000/None ...  - acc: 0.4498 - loss: 2.0474 - top_k_categorical_accuracy: 0.7666\n",
            "step: 8000/None ...  - acc: 0.4735 - loss: 1.9341 - top_k_categorical_accuracy: 0.7903\n",
            "step: 9000/None ...  - acc: 0.4948 - loss: 1.8367 - top_k_categorical_accuracy: 0.8076\n",
            "step: 10000/None ...  - acc: 0.5110 - loss: 1.7747 - top_k_categorical_accuracy: 0.8191\n",
            "step: 11000/None ...  - acc: 0.5321 - loss: 1.6789 - top_k_categorical_accuracy: 0.8373\n",
            "step: 12000/None ...  - acc: 0.5443 - loss: 1.6238 - top_k_categorical_accuracy: 0.8461\n",
            "step: 13000/None ...  - acc: 0.5538 - loss: 1.5713 - top_k_categorical_accuracy: 0.8554\n",
            "step: 14000/None ...  - acc: 0.5654 - loss: 1.5242 - top_k_categorical_accuracy: 0.8630\n",
            "step: 15000/None ...  - acc: 0.5767 - loss: 1.4742 - top_k_categorical_accuracy: 0.8705\n",
            "step: 16000/None ...  - acc: 0.5881 - loss: 1.4270 - top_k_categorical_accuracy: 0.8780\n",
            "step: 17000/None ...  - acc: 0.5947 - loss: 1.4048 - top_k_categorical_accuracy: 0.8825\n",
            "step: 18000/None ...  - acc: 0.5971 - loss: 1.3811 - top_k_categorical_accuracy: 0.8858\n",
            "step: 19000/None ...  - acc: 0.6064 - loss: 1.3418 - top_k_categorical_accuracy: 0.8920\n",
            "step: 20000/None ...  - acc: 0.6134 - loss: 1.3145 - top_k_categorical_accuracy: 0.8967\n",
            "step: 21000/None ...  - acc: 0.6248 - loss: 1.2745 - top_k_categorical_accuracy: 0.9036\n",
            "step: 22000/None ...  - acc: 0.6296 - loss: 1.2526 - top_k_categorical_accuracy: 0.9067\n",
            "step: 23000/None ...  - acc: 0.6341 - loss: 1.2315 - top_k_categorical_accuracy: 0.9102\n",
            "step: 24000/None ...  - acc: 0.6409 - loss: 1.2055 - top_k_categorical_accuracy: 0.9135\n",
            "step: 25000/None ...  - acc: 0.6442 - loss: 1.1925 - top_k_categorical_accuracy: 0.9149\n",
            "step: 26000/None ...  - acc: 0.6495 - loss: 1.1741 - top_k_categorical_accuracy: 0.9176\n",
            "step: 27000/None ...  - acc: 0.6526 - loss: 1.1609 - top_k_categorical_accuracy: 0.9200\n",
            "step: 28000/None ...  - acc: 0.6611 - loss: 1.1308 - top_k_categorical_accuracy: 0.9228\n",
            "step: 29000/None ...  - acc: 0.6641 - loss: 1.1132 - top_k_categorical_accuracy: 0.9261\n",
            "step: 30000/None ...  - acc: 0.6687 - loss: 1.0992 - top_k_categorical_accuracy: 0.9281\n",
            "step: 31000/None ...  - acc: 0.6646 - loss: 1.1073 - top_k_categorical_accuracy: 0.9274\n",
            "step: 32000/None ...  - acc: 0.6751 - loss: 1.0634 - top_k_categorical_accuracy: 0.9327\n",
            "step: 33000/None ...  - acc: 0.6814 - loss: 1.0464 - top_k_categorical_accuracy: 0.9341\n",
            "step: 34000/None ...  - acc: 0.6821 - loss: 1.0449 - top_k_categorical_accuracy: 0.9348\n",
            "step: 35000/None ...  - acc: 0.6856 - loss: 1.0302 - top_k_categorical_accuracy: 0.9358\n",
            "step: 36000/None ...  - acc: 0.6876 - loss: 1.0205 - top_k_categorical_accuracy: 0.9385\n",
            "step: 37000/None ...  - acc: 0.6916 - loss: 1.0050 - top_k_categorical_accuracy: 0.9400\n",
            "step: 38000/None ...  - acc: 0.6881 - loss: 1.0199 - top_k_categorical_accuracy: 0.9373\n",
            "step: 39000/None ...  - acc: 0.6963 - loss: 0.9840 - top_k_categorical_accuracy: 0.9429\n",
            "step: 40000/None ...  - acc: 0.7035 - loss: 0.9618 - top_k_categorical_accuracy: 0.9460\n",
            "step: 41000/None ...  - acc: 0.7065 - loss: 0.9454 - top_k_categorical_accuracy: 0.9475\n",
            "step: 42000/None ...  - acc: 0.7083 - loss: 0.9335 - top_k_categorical_accuracy: 0.9487\n",
            "step: 43000/None ...  - acc: 0.7111 - loss: 0.9332 - top_k_categorical_accuracy: 0.9495\n",
            "step: 44000/None ...  - acc: 0.7144 - loss: 0.9195 - top_k_categorical_accuracy: 0.9505\n",
            "step: 45000/None ...  - acc: 0.7183 - loss: 0.9069 - top_k_categorical_accuracy: 0.9519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b200020d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "metadata": {
        "id": "8leBniFNsN_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "81b62b44-128d-452f-c552-c2288568812e"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test,y_test_k)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 294us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0736297103881838, 0.5116, 0.7886]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "metadata": {
        "id": "5vuVIkMw2aZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Top 5 accuracy is 78%"
      ]
    },
    {
      "metadata": {
        "id": "EZ4q_jfy2jU_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conclusion and Customization\n",
        "\n",
        "More or less my customization moves have been to increase or decrease convolutional filter numbers or size, use pooling and batch normalization either frequently or infrequently and increase the size and width of dense layers.\n",
        "\n",
        "Another step i took was to convert to keras, for some reason this increased performance even though I cannot figure out the difference between the two. As far as I can tell the graphs are the same. I think Keras has some kind of early stopping on bad training cycles that is not default in TensorFlow.\n",
        "\n",
        "It is questionable if the learning rate decay I used is useful. I was hinted onto it from Jacob Maarek, and he gave me some scale for the decay which i built into my smooth function. I didn't have enough time to explore all the parameters, so I think I could boost this with a simpler optimizer than Adams so I would have more control over the decay."
      ]
    },
    {
      "metadata": {
        "id": "4w_eD1Kg6ZqL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}